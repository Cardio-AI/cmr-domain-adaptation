{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define logging and working directory\n",
    "import os\n",
    "# define GPU id to use\n",
    "# 0 = 1080 Bus ID 2\n",
    "# 1 = Titan Bus ID 131\n",
    "# 2 = Titan Bus ID 132\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "current_gpu = '/device:GPU:0'\n",
    "\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import platform\n",
    "import SimpleITK as sitk\n",
    "import glob\n",
    "import datetime\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from medpy.metric.binary import hd, dc,jc,precision,recall\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "# setup working directory\n",
    "print(os.getcwd())\n",
    "# change working directory to project root - neccessary for jupyter notebooks\n",
    "if platform.system() is \"Windows\":\n",
    "    os.chdir('E:\\\\sven\\\\git\\\\cardio')\n",
    "else:\n",
    "    os.chdir('/Users/minority/Code/Git/cardio')\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "from src.utils.utils_io import Console_and_file_logger, ensure_dir, save_config\n",
    "from src.utils.myshow import myshow, myshow3d\n",
    "from src.visualization.visualize import plot_3d_vol, plot_4d_vol\n",
    "from src.data.dataset import get_metadata_maybe, filter_4d_vol, describe_sitk\n",
    "from src.data.generators import DataGenerator3D\n",
    "from src.data.dataset import get_3d_img_msk_files\n",
    "from src.utils.my_metrics import jaccard_coef, jaccard_coef_background, jaccard_coef_rv, jaccard_coef_lv, jaccard_coef_myo, bce_dice_iou_loss, weighted_categorical_crossentropy, cce_dice_loss, weighted_cce_dice_coef\n",
    "from src.utils.unet_3d_metrics import weighted_dice_coefficient_loss\n",
    "from src.models.ModelManager import create_3D_unet\n",
    "from src.utils.KerasCallbacks import TrainValTensorBoard, CustomImageWriter3D\n",
    "\n",
    "\n",
    "\n",
    "# define experiment name for report, model and log paths + filenames\n",
    "EXPERIMENT = '3D_unet_cce_dice_loss'\n",
    "now = datetime.datetime.now()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\sven\\git\\cardio\n",
      "E:\\sven\\git\\cardio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define logging and working directory\n",
    "# define logging and working directory\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import platform\n",
    "print(os.getcwd())\n",
    "# change working directory to project root - neccessary for jupyter notebooks\n",
    "if platform.system() is \"Windows\":\n",
    "    os.chdir('E:\\\\sven\\\\git\\\\cardio')\n",
    "else:\n",
    "    os.chdir('/Users/minority/Code/Git/cardio')\n",
    "print(os.getcwd())\n",
    "\n",
    "# define GPU id to use\n",
    "# 0 = 1080 Bus ID 2\n",
    "# 1 = Titan Bus ID 131\n",
    "# 2 = Titan Bus ID 132\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "current_gpu = '/device:GPU:0'\n",
    "\n",
    "from src.utils.utils_io import Console_and_file_logger, ensure_dir, save_config\n",
    "from src.utils.myshow import myshow, myshow3d\n",
    "import src.utils.my_metrics as metr\n",
    "import src.utils.medley_metrics as m_metrics\n",
    "from src.data.dataset import load_data, load_acdc_data\n",
    "from src.utils.Evaluation import sanity_check\n",
    "from src.visualization.visualize import plot_confusion_matrix, show_slice\n",
    "\n",
    "from src.visualization.visualize import plot_3d_vol, plot_4d_vol\n",
    "from src.data.dataset import get_metadata_maybe, filter_4d_vol, describe_sitk\n",
    "from src.data.generators import DataGenerator3D\n",
    "from src.data.dataset import get_3d_img_msk_files\n",
    "\n",
    "from medpy.metric.binary import hd, dc,jc,precision,recall\n",
    "\n",
    "Console_and_file_logger('Evaluation', logging.INFO)\n",
    "\n",
    "import glob\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import json\n",
    "\n",
    "from ipywidgets import interact\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "metrics = [\n",
    "    metr.jaccard_coef,\n",
    "    metr.jaccard_coef_background,\n",
    "    metr.jaccard_coef_myo,\n",
    "    metr.jaccard_coef_lv,\n",
    "    metr.jaccard_coef_rv,\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdea6f12f1864e3dbd9357f645dba4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='config_file', options=('reports/configs\\\\2d_unet_acdc\\\\2019-03-09_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def load_config(config_file=glob.glob('reports/configs/**/**/*.json', recursive=False), load=False):\n",
    "    \"\"\"\n",
    "    load config, tranings history and model\n",
    "    \"\"\"\n",
    "    # load config with all params into global namespace\n",
    "\n",
    "    with open(config_file, encoding='utf-8') as data_file:\n",
    "        config = json.loads(data_file.read())\n",
    "    #globals().update(config)\n",
    "    globals()['config'] = config\n",
    "    logging.info('Experiment: {}'.format(config['EXPERIMENT']))\n",
    "    logging.info('config:\\n {}'.format(json.dumps(config, indent=4, sort_keys=True)))\n",
    "    Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "\n",
    "\n",
    "    # load all experiment files if user asked for it\n",
    "    if load:\n",
    "\n",
    "        glob_ = {}\n",
    "        try:\n",
    "            # load trainings history\n",
    "            logging.info('loading trainings history...')\n",
    "            glob_['df_history'] = pd.read_csv(os.path.join(HISTORY_PATH, EXPERIMENT + '.csv'),index_col=0)\n",
    "            logging.info('history {} loaded'.format(os.path.join(HISTORY_PATH, EXPERIMENT + '.csv')))\n",
    "        except Exception as e:\n",
    "            logging.info(str(e))\n",
    "\n",
    "        try:\n",
    "            # load model\n",
    "            logging.info('loading model...')\n",
    "            model = model_from_json(open(os.path.join(MODEL_PATH, 'model.json')).read())\n",
    "            model.load_weights(os.path.join(MODEL_PATH, 'checkpoint.h5'))\n",
    "            model.compile(optimizer=OPTIMIZER, loss=keras.losses.categorical_crossentropy, metrics=metrics)\n",
    "            glob_['model'] = model\n",
    "            logging.info('model {} loaded'.format(os.path.join(MODEL_PATH, 'model.json')))\n",
    "        except Exception as e:\n",
    "            logging.info(str(e))\n",
    "        \n",
    "\n",
    "        try:\n",
    "            # load past evaluations done with that model\n",
    "            logging.info('loading past evaluation scores...')\n",
    "            glob_['evaluation_score'] = pd.read_csv(os.path.join('reports/evaluation/', EXPERIMENT + '.csv')).set_index('Evaluation')\n",
    "            logging.info('past evaluation scores {} loaded'.format(os.path.join('reports/evaluation/', EXPERIMENT + '.csv')))\n",
    "        except Exception as e:\n",
    "            # delete the evaluation score object from current namespace if past models & evaluations have beend done\n",
    "            globals().pop('evaluation_score', None)\n",
    "            logging.info(str(e))\n",
    "        # update global namesspace for further tests\n",
    "        globals().update(glob_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 18:49:41,827 INFO x_train files: 757, y_train files: 757\n",
      "2019-04-26 18:49:41,827 INFO x_val files: 126, y_val files: 126\n",
      "2019-04-26 18:49:41,827 INFO x_test files: 127, y_test files: 127\n",
      "2019-04-26 18:49:41,827 INFO Create DataGenerator\n",
      "2019-04-26 18:49:41,827 INFO No augmentation\n",
      "2019-04-26 18:49:41,827 INFO Create DataGenerator\n",
      "2019-04-26 18:49:41,827 INFO No augmentation\n",
      "2019-04-26 18:49:41,827 INFO Create DataGenerator\n",
      "2019-04-26 18:49:41,827 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "x_train_f, y_train_f = get_3d_img_msk_files('data/raw/tetra/3D/train/')\n",
    "x_val_f, y_val_f = get_3d_img_msk_files('data/raw/tetra/3D/val/')\n",
    "x_test_f, y_test_f = get_3d_img_msk_files('data/raw/tetra/3D/test/')\n",
    "\n",
    "logging.info('x_train files: {}, y_train files: {}'.format(len(x_train_f), len(y_train_f)))\n",
    "logging.info('x_val files: {}, y_val files: {}'.format(len(x_val_f), len(y_val_f)))\n",
    "logging.info('x_test files: {}, y_test files: {}'.format(len(x_test_f), len(y_test_f)))\n",
    "\n",
    "# create a batch generator, filter size, for faster testing\n",
    "batch_generator = DataGenerator3D(x_train_f, y_train_f, batch_size=config['BATCHSIZE'], dim=(config['IMG_Z'], config['IMG_WIDTH'], config['IMG_HEIGHT']), spacing=(1.25,1.25,8), mask_values=MASK_VALUES)\n",
    "validation_generator = DataGenerator3D(x_val_f, y_val_f, batch_size=config['BATCHSIZE'], dim=(config['IMG_Z'], config['IMG_WIDTH'], config['IMG_HEIGHT']), spacing=(1.25,1.25,8), mask_values=MASK_VALUES)\n",
    "test_generator = DataGenerator3D(x_test_f, y_test_f, dim=(config['IMG_Z'], config['IMG_WIDTH'], config['IMG_HEIGHT']), spacing=(1.25,1.25,8), mask_values=MASK_VALUES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 18:49:47,225 INFO load and predict 127 batches\n",
      "2019-04-26 18:52:08,397 INFO gt shape: (128, 12, 256, 256, 4)\n",
      "2019-04-26 18:52:08,412 INFO pred shape: (128, 12, 256, 256, 4)\n"
     ]
    }
   ],
   "source": [
    "# predict for all batches\n",
    "from medpy.metric.binary import hd, dc,jc,precision,recall\n",
    "import numpy as np\n",
    "gt_ = []\n",
    "pred_ = []\n",
    "img_ = []\n",
    "n_batches = len(test_generator)\n",
    "#n_batches = 2\n",
    "logging.info('load and predict {} batches'.format(n_batches))\n",
    "#with tf.device(current_gpu):\n",
    "#    pred = model.predict_generator(batch_generator, steps = len(batch_generator))\n",
    "#\n",
    "#gt_ = [gt_.extend(batch[1]) for batch in batch_generator]\n",
    "    \n",
    "\n",
    "\n",
    "for idx,batch in enumerate(test_generator):\n",
    "    if idx <= n_batches:\n",
    "        with tf.device(current_gpu):\n",
    "            img_.extend(batch[0])\n",
    "            pred_.extend(((model.predict_on_batch(batch[0]))>=0.5).astype(np.bool))\n",
    "        gt_.extend(batch[1])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# reshape\n",
    "gt = np.array(gt_)\n",
    "pred = np.array(pred_)\n",
    "\n",
    "logging.info('gt shape: {}'.format(gt.shape))\n",
    "logging.info('pred shape: {}'.format(pred.shape))\n",
    "del gt_\n",
    "del pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-26 18:52:16,120 INFO jac: 0.9945014631047002\n",
      "2019-04-26 18:52:16,120 INFO dice: 0.9972431522377825\n",
      "2019-04-26 18:52:16,120 INFO prec: 0.9974677345929726\n",
      "2019-04-26 18:52:16,120 INFO recall: 0.9970186709903857\n",
      "2019-04-26 18:52:19,150 INFO jac: 0.8124138991646308\n",
      "2019-04-26 18:52:19,150 INFO dice: 0.8964993035410783\n",
      "2019-04-26 18:52:19,150 INFO prec: 0.8901523341423578\n",
      "2019-04-26 18:52:19,150 INFO recall: 0.9029374333290774\n",
      "2019-04-26 18:52:22,114 INFO jac: 0.6954737983400961\n",
      "2019-04-26 18:52:22,114 INFO dice: 0.8203887303017946\n",
      "2019-04-26 18:52:22,114 INFO prec: 0.7650892389977327\n",
      "2019-04-26 18:52:22,114 INFO recall: 0.8843049528235855\n",
      "2019-04-26 18:52:25,268 INFO jac: 0.8747032837333085\n",
      "2019-04-26 18:52:25,268 INFO dice: 0.9331645080296792\n",
      "2019-04-26 18:52:25,268 INFO prec: 0.9483716122535772\n",
      "2019-04-26 18:52:25,268 INFO recall: 0.9184373978424322\n"
     ]
    }
   ],
   "source": [
    "# calc IOU per channel\n",
    "for c in range(pred.shape[-1]):\n",
    "    pred_ = pred[...,c]\n",
    "    gt_ = gt[...,c]\n",
    "    # calc medpy scores\n",
    "    jaccard_coef = jc(pred_, gt_)\n",
    "    dice_score = dc(pred_, gt_)\n",
    "    precision_score = precision(pred_, gt_)\n",
    "    recall_score = recall(pred_, gt_)\n",
    "\n",
    "    logging.info('jac: {}'.format(jaccard_coef))\n",
    "    logging.info('dice: {}'.format(dice_score))\n",
    "    logging.info('prec: {}'.format(precision_score))\n",
    "    logging.info('recall: {}'.format(recall_score))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903cc78f36e7471db317d96ff7d5977a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='data/raw/tetra/3D/test/', description='path'), Checkbox(value=False, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def evaluate_with_path(path='data/raw/tetra/3D/test/',start=False,):\n",
    "    \"\"\"\n",
    "    Run model evaluation with all compiled metrics for a given directory\n",
    "    \"\"\"\n",
    "    if start:\n",
    "        path_as_string = path.replace('/','_')\n",
    "        \n",
    "        # load data sliced\n",
    "        x_train_f, y_train_f = get_3d_img_msk_files(path)\n",
    "\n",
    "        # predict testdata\n",
    "        test_generator = DataGenerator3D(x_train_f, y_train_f, batch_size=config['BATCHSIZE'], dim=(config['IMG_Z'], config['IMG_WIDTH'], config['IMG_HEIGHT']), spacing=(1.25,1.25,8), mask_values=MASK_VALUES)\n",
    "\n",
    "        with tf.device(current_gpu):\n",
    "            scores = model.evaluate_generator(test_generator, max_queue_size=10, verbose=1)\n",
    "\n",
    "        \n",
    "        # get, or create a dataframe from results, and store results in global namespace\n",
    "        col = ['Evaluation'] +  model.metrics_names\n",
    "        row = scores\n",
    "        # get evaluation score from global namespace, or create a new one\n",
    "        scores_df = globals().get('evaluation_score', pd.DataFrame(columns=col).set_index('Evaluation'))\n",
    "        scores_df.loc[path_as_string] = row\n",
    "        \n",
    "                                  \n",
    "        globals()['evaluation_score'] = scores_df\n",
    "        export_path = os.path.join('reports/evaluation', EXPERIMENT)\n",
    "        ensure_dir(export_path)\n",
    "        scores_df.to_csv(os.path.join(export_path, 'metrics_' + path_as_string + '.csv'))\n",
    "        return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del evaluation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardio",
   "language": "python",
   "name": "cardio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
